---
title: "Dada2 tutorial"
output:
  github_document:
    toc: true
    toc_depth: 2
---
# getting ready
Nous chargeons d'abord le dada2package

```{r message=FALSE}
library("dada2")
```

Définir la variable path suivante pour qu'elle pointe vers le répertoire Miseq_sop extrait sur la machine.
Les données utilisées sont dans le Mothur MiSeq SOP. Ces fichiers fastq ont été générés par séquençage d'amplicon 2x250 Illumina Miseq de la région V4 du gène de l'ARNr 16S à partir d'échantillons d'intestin prélevés longitudinalement à partir d'une souris après le sevrage. Pour l'instant, considérez simplement les fichiers fastq appariés à traiter.

```{r, results='hide'}
path <- "~/github/ecog2_cc1_final/ecog2_cc1/MiSeq_SOP" # CHANGE ME to the directory containing the fastq files after unzipping.
list.files(path)
```

cela permet de lire les noms des fichiers fastq et effectuons quelques manipulations de chaînes pour obtenir des listes correspondantes des fichiers fastq  forward et reverse.
On va créer une variable fnFs et on lui assigne la valeur de résultat de la fonction sort qui va classer les résultats de la fonction list.filesqui va lister le fichier R1_001.fastq et va faire la même chose pour R2_001.fastq.
En suite on va extrairer les sample names avec la fonction strsplit(), en supposant que les noms de fichiers ont le format: SAMPLENAME_XXX.fastq
```{r}
# Forward and reverse fastq filenames have format: SAMPLENAME_R1_001.fastq and SAMPLENAME_R2_001.fastq
fnFs <- sort(list.files(path, pattern="_R1_001.fastq", full.names = TRUE))
fnRs <- sort(list.files(path, pattern="_R2_001.fastq", full.names = TRUE))
# Extract sample names, assuming filenames have format: SAMPLENAME_XXX.fastq
sample.names <- sapply(strsplit(basename(fnFs), "_"), `[`, 1)
```

# Inspect read quality profiles
Nous commençons par visualiser les profils de qualité des Forward reads en utilisant la fonction plotQualityProfile qui va permettre de tracer un résumé visuel de la distribution des scores de qualité en fonction de la position de la séquence pour le fichier: fnFs fastq d'entrée.

```{r message=FALSE, warning=FALSE}
plotQualityProfile(fnFs[1:2])
```

Les lectures avant sont de bonne qualité. mais on rogner quand même les derniers nucléotides pour éviter des erreurs moins bien contrôlées qui peuvent s'y produire. on va tronquer donc les lectures avant à la position 240 (en coupant les 10 derniers nucléotides).


on visualise le profil de qualité des reverse reads en utilisant la fonction plotQualityProfile qui va permettre de tracer un résumé visuel de la distribution des scores de qualité en fonction de la position de la séquence pour le fichier: fnRs fastq d'entrée.

```{r}
plotQualityProfile(fnRs[1:2])
```

Comentaire de graphe au dessus: sur ce graphe on remarque que la qualité est moins bonne que celle du graphe d'avant, on tranque donc les lectures inversées à la position 160 où la distribution de qualité se bloque.

# Filter and trim
Attribuer les noms de fichiers aux fichiers fastq.gz filtrés.
on crée une variable filtFs et on met dedans _F_filt.fastq.gz
et puis une filtRs et on met dedans _R_filt.fastq.gz
après on nome l'objet filtFs en utilisant la fonction names on fait pareil pour filtRs et on leur donne le nom sample.names qui est la valeur de la fonction.

```{r}
# Place filtered files in filtered/ subdirectory
filtFs <- file.path(path, "filtered", paste0(sample.names, "_F_filt.fastq.gz"))
filtRs <- file.path(path, "filtered", paste0(sample.names, "_R_filt.fastq.gz"))
names(filtFs) <- sample.names
names(filtRs) <- sample.names
```

Nous utiliserons les paramètres de filtrage standard: maxN=0(DADA2 ne nécessite aucun Ns) truncQ=2, rm.phix=TRUEet maxEE=2. Le aramètre maxEEp définit le nombre maximum d '«erreurs attendues» autorisées dans une lecture.
Ici, on crée une variale out et on lui assigne les valeurs des résultats de la fonction filterAndTrim(), qui va filtrer et ajuster les fichiers fnFs, filtFs, fnRs, filtRs de  fastq d'entrée (peut être compressé) en fonction de plusieurs critères:  maxN=0, maxEE=c(2,2), truncQ=2, rm.phix=TRUE,
compress=TRUE, multithread=TRUE , et génère des fichiers fastq (compressés par défaut) contenant les lectures coupées qui ont passé les filtres. Des fichiers fastq revers et forward correspondants peuvent être fournis en entrée, auquel cas le filtrage est effectué sur les lectures avant et arrière indépendamment, et les deux lectures doivent passer pour que la paire de lecture soit sortie.
En suite on va utiliser la fonction head pour avoir un apperçu de l'objet out

```{r message=FALSE}
out <- filterAndTrim(fnFs, filtFs, fnRs, filtRs, truncLen=c(240,160),
              maxN=0, maxEE=c(2,2), truncQ=2, rm.phix=TRUE,
              compress=TRUE, multithread=TRUE) # On Windows set multithread=FALSE
head(out)
```

# appretissage des erreurs

dada2 calcul un model d'erreurs apartir des données de séquençage, cette méthode sur les reads F Reverse. 
L'algorithme DADA2 utilise un modèle d'erreur paramétrique ( err) et chaque jeu de données d'amplicon a un ensemble différent de taux d'erreur. La learnErrors méthode apprend ce modèle d'erreur à partir des données, en alternant l'estimation des taux d'erreur et l'inférence de la composition de l'échantillon jusqu'à ce qu'ils convergent vers une solution cohérente conjointement. 

```{r}
errF <- learnErrors(filtFs, multithread=TRUE)
```
dada2 calcul un model d'erreurs apartir des données de séquençage, cette méthode sur les reads Reverse de la même manière que pour errF

```{r}
errR <- learnErrors(filtRs, multithread=TRUE)
```

le code suivant est pour vérifier si rien d'autre, de visualiser les taux d'erreur estimés en utilisant la fonction plotErrors. Cette fonction va tracer la fréquence observée de chaque transition (par exemple A-> C) en fonction du score de qualité associé. Il trace également les taux d'erreur estimés finaux (s'ils existent). l'argument nominalQ=TRUE va permettre de tracer les taux d'erreur attendus (ligne rouge) si les scores de qualité correspondent exactement à leur définition nominale: Q = -10 log10 (p_err).

```{r message=FALSE}
plotErrors(errF, nominalQ=TRUE)
```
Intérprétation de graphe précédent: graphe 1: la probabilité que A est A doit être max ainsi de suite...
les taux d'erreur pour chaque transition sont indiquées sur les graphes (graphe 2: A-->C etc)
c2: probabilité d'erreus de séq pour qu'un A soit un C.
 Ici, les taux d'erreur estimés (ligne noire) correspondent bien aux taux observés (points), et les taux d'erreur diminuent avec une qualité accrue comme prévu. Tout semble raisonnable et nous procédons en toute confiance.

# sample inference
on crée une nouvelle variable dadaFs pour corriger les jeux de données
dada appliquée au donné Forward.
La fonction dada supprime toutes les erreurs de séquençage pour révéler les membres de la communauté séquencée. l'argument multithread=TRUE: le multithreading est activé et le nombre de threads disponibles est automatiquement déterminé. Si un entier est fourni, le nombre de threads à utiliser est défini en transmettant l'argument à setThreadOptions.

```{r}
dadaFs <- dada(filtFs, err=errF, multithread=TRUE)
```
dada appliqué au donné reverse
on crée une nouvelle variable dadaRs et on lui assigne la valeur de résultat de la fonction dada comme on a fait pour les reverse à fin de corriger les jeux de données appliquées pour les Reverse.

```{r}
dadaRs <- dada(filtRs, err=errR, multithread=TRUE)
```

dada a crée des objet de class dada: dadaFs et dada Rs
on regarde ce qui est dans le premier étagers du placard de dadaFS, on peut changer le 1 pour regarder à n'importe quel étage de dadaFS.

```{r}
dadaFs[[1]]
```

# mairged paired reads

on va merger Read 1 et read 2 pour obtenir les séquences entièrement débruitées en utilisant la fonction mergePairs(). La fusion est effectuée en alignant les lectures avant débruitées avec le complément inverse des lectures inverses débruitées correspondantes, puis en construisant les séquences «contig» fusionnées.
verbose=TRUE:monter les étape avec le texte
head(mergers[[1]]):inspecter les résultats en regardant les premières lignes

```{r}
mergers <- mergePairs(dadaFs, filtFs, dadaRs, filtRs, verbose=TRUE)
# Inspect the merger data.frame from the first sample
head(mergers[[1]])
```

Donc là on a les reads fusionnés avec succès.

# construire la table d'observation

à partir des merged, on crée un nouvelle objet seqtab 
la fonction va permettre de construire une table de séquence (analogue à une table OTU) à partir de la liste d'échantillon mergers.
la fonction dim va permettre de récupérer l'objet seqtab.
 
```{r}
seqtab <- makeSequenceTable(mergers)
dim(seqtab)
```
regarder la distribution de la longeur des séquences.
La table de séquence est une matrix avec des lignes correspondant aux (et nommées par) les échantillons, et des colonnes correspondant (et nommées par) les variantes de séquence. 

```{r}
# Inspect distribution of sequence lengths
table(nchar(getSequences(seqtab)))
```
dans mon objet seqtab j'ai une séq qui fait 251 paires de bases, une autre qui fait 252 etc

# Remove chimeras

une chimère: ça se passe pendant l'amplification par PCR
donc par ex un ADN 16s amplifier par un fragment reverse et forrward.
Si on prend que le forward,y aura élongation mais imaginant qu'elle s'arréte avant la fin de la séq 16S.
Donc on va avoir le fragment 16S qui n'a pas bouger et un fragment non complet. donc àprès le 2ème cycle, le fragment non complet va pouvoir s'hybrider avec un 16s d'une autre bactérie, et l'élongation va continuer.
on va avoir comme résultat au final un fragment hybride qui provient du premier ARN 16 et du deuxième.
cela s'appelle chimère.
On va éliminer ces chimères en utlisant la fonction removeBimeraDenovo
le système va regarder tout les séq rares dans le début contig correspont au premier ARN et la fin au deuxième.

```{r message=FALSE}
seqtab.nochim <- removeBimeraDenovo(seqtab, method="consensus", multithread=TRUE, verbose=TRUE)
dim(seqtab.nochim)
```
Donc le résultat montre qui il a détectrer 61 (=293-232) chimère sur 293(= 1+88+196+6+2).

calcul de ratio chimère qui est égale à la somme des sequences se trouvant dans l'objet seqtab.mochim (c'est l'objet après remove des chimères) / somme des séquences se traouvent dans l'objet seqtab(avant d'enlever les chimères)

```{r}
sum(seqtab.nochim)/sum(seqtab)
```

y a (1-0.96)*100 = 3.5% de séq chimériques dans notre jeu de données.
les chimères représentent environ 21% des variantes de séquence fusionnées, mais lorsque nous tenons compte de l'abondance de ces variantes, nous voyons qu'elles ne représentent qu'environ 4% des lectures de séquence fusionnée.

# Track reads through the pipeline

résumé des fichiers qualité.
construire une table 
on crée un nouvel objet qui est getN c'est une variable qui prend le rôle d'une fonction
apliquer la fonnction get N qui est la somme des get uniq de dadaFS
la table track va être la concaténation de tout ce qui est entre parentèse.
head(track) : pour visualiser le tableau

```{r}
getN <- function(x) sum(getUniques(x))
track <- cbind(out, sapply(dadaFs, getN), sapply(dadaRs, getN), sapply(mergers, getN), rowSums(seqtab.nochim))
# If processing a single sample, remove the sapply calls: e.g. replace sapply(dadaFs, getN) with getN(dadaFs)
colnames(track) <- c("input", "filtered", "denoisedF", "denoisedR", "merged", "nonchim")
rownames(track) <- sample.names
head(track)
```

On a conservé la majorité des lectures brutes et aucune baisse trop importante n'est associée à une seule étape.

# assignation de la taxonomie

il va regarder dans le base de données et à partir des séq qui sont proches, et va assigner une taxonomie.

c'est une façon d'attribuer une taxonomie aux séquences.
La fonction assignTaxonomy prend en entrée un ensemble de séquences à classer et un ensemble d'apprentissage de séquences de référence avec une taxonomie connue (silva en ce cas), et produit des affectations taxonomiques avec au moins une minBootconfiance bootstrap.


```{r}
taxa <- assignTaxonomy(seqtab.nochim, "~/silva_nr99_v138_train_set.fa.gz", multithread=TRUE)
```

ajout d'espèces, téléchargement du fichier et le placer dans le répertoire taxa contenant les fichiers fastq.

```{r}
taxa <- addSpecies(taxa, "~/silva_species_assignment_v138.fa.gz")
```

Inspecter les affectations taxonomiques:

```{r}
taxa.print <- taxa # Removing sequence rownames for display only
rownames(taxa.print) <- NULL
head(taxa.print)
```

les Bacteroidetes sont bien représentés parmi les taxons les plus abondants dans ces échantillons fécaux. Peu d'attributions d'espèces ont été faites, à la fois parce qu'il est souvent impossible de faire des assignations d'espèces sans ambiguïté à partir de sous-segments du gène 16S, et parce qu'il y a étonnamment peu de couverture du microbiote intestinal de souris indigène dans les bases de données de référence.

# Evaluate accuracy

L'un des échantillons inclus ici était une «communauté fictive», dans laquelle un mélange de 20 souches connues a été séquencé (cette communauté fictive est supposée être de 21 souches, mais P. acnes est absent des données brutes). Les séquences de référence correspondant à ces souches ont été fournies dans l'archive zip téléchargée. Nous revenons à cet échantillon et comparons les variantes de séquence inférées par DADA2 à la composition attendue de la communauté.

cat permet de faire sortir les objets en concaténant les représentations

```{r}
unqs.mock <- seqtab.nochim["Mock",]
unqs.mock <- sort(unqs.mock[unqs.mock>0], decreasing=TRUE) # Drop ASVs absent in the Mock
cat("DADA2 inferred", length(unqs.mock), "sample sequences present in the Mock community.\n")
```

On décrit match.ref 

```{r}
mock.ref <- getSequences(file.path(path, "HMP_MOCK.v35.fasta"))
match.ref <- sum(sapply(names(unqs.mock), function(x) any(grepl(x, mock.ref))))
cat("Of those,", sum(match.ref), "were exact matches to the expected reference sequences.\n")
```

Cette fausse communauté contenait 20 souches bactériennes. DADA2 a identifié 20 ASV qui correspondent tous exactement aux génomes de référence des membres attendus de la communauté. Le taux d'erreur résiduel après le pipeline DADA2 pour cet échantillon est donc de 0% .

```{r}
save.image(file="02_data-analysis")
```








